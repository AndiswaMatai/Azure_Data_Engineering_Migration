# Azure Data Engineering Migration Portfolio â€“ Project Documentation

This document contains **README content, architecture descriptions, pipeline logic, scripts outline, and governance documentation** for all three Azure Data Engineering projects. Each section can be copied directly into its respective project folder.

---

# ðŸš€ Project 1: Azure Data Platform for Fleet & Financial Reporting

## ðŸ“Œ README.md

### Overview

End-to-end Azure data platform designed to consolidate fleet operational data and financial metrics into a unified analytics layer for executive reporting.

### Business Problem

* Fragmented on-prem SQL Server systems
* Manual reporting cycles and inconsistent KPIs
* Slow access to operational and financial insights

### Solution Summary

* Automated ingestion from on-prem SQL Server using Azure Data Factory
* Lakehouse architecture on ADLS Gen2 (Raw â†’ Curated â†’ Analytics)
* Transformations using Azure Databricks (Python & SQL)
* Power BI dashboards built on Synapse semantic models

### Business Impact

* Fleet utilization improved to **85.6%**
* Downtime reduced to **320 hours**
* Reporting turnaround reduced from **45 hours to <10 hours**
* Financial reporting standardized in **ZAR**

---

## ðŸ—ï¸ Architecture Diagram (Description)

**Flow:**

1. Onâ€‘Prem SQL Server â†’ Azure Data Factory (Selfâ€‘Hosted IR)
2. ADLS Gen2 â€“ Raw Zone (Parquet)
3. Databricks â€“ Cleansing, joins, business rules
4. ADLS Gen2 â€“ Curated & Analytics Zones
5. Azure Synapse â€“ External tables & views
6. Power BI â€“ Executive dashboards

*(Diagram labels: Security via Azure AD, Secrets via Key Vault)*

---

## ðŸ”§ Pipeline & Script Logic

### ADF

* Full & incremental extraction using watermark on `LastUpdatedDate`
* Parameterized pipelines for reusability

### Databricks

* Schema enforcement
* Fleet KPIs (utilization %, downtime hours)
* Financial aggregations by period

---

## ðŸ“„ Governance & Security

* Azure AD RBAC
* Data access by zone (Raw restricted)
* Audit logging enabled

---

# ðŸ“Š Project 2: SQL Server â†’ Power BI Modernization

## ðŸ“Œ README.md

### Overview

Modernization of legacy SQL Server reporting into a scalable, cloudâ€‘native Azure analytics platform enabling selfâ€‘service BI.

### Business Problem

* Manual Excel extracts
* Long refresh cycles
* Limited scalability and access control

### Solution Summary

* Automated ingestion via Azure Data Factory
* Transformations using Databricks
* Synapse analytics layer for Power BI
* Certified datasets for enterprise use

### Business Impact

* Reporting latency reduced to **~12 hours**
* Power BI adoption scaled to **550+ users**
* Departmentâ€‘level drilldowns enabled
* Financial KPIs reported in **ZAR**

---

## ðŸ—ï¸ Architecture Diagram (Description)

**Flow:**
SQL Server â†’ ADF â†’ ADLS Gen2 â†’ Databricks â†’ Synapse â†’ Power BI Service

**Key Concepts:**

* Star schema modeling
* Certified datasets
* Incremental refresh

---

## ðŸ”§ Pipeline & Script Logic

### Databricks

* Dimension & fact table construction
* Surrogate keys
* Slowly Changing Dimensions (Type 2)

### Power BI

* Semantic model with measures
* Row Level Security (RLS)

---

## ðŸ“„ Governance

* Dataset certification
* Workspace separation (Dev / Test / Prod)
* Refresh monitoring

---

# âš¡ Project 3: Azure Incremental Data Pipeline (Streamingâ€‘Style)

## ðŸ“Œ README.md

### Overview

Highâ€‘performance incremental ingestion pipeline for highâ€‘volume mobility data using watermarkâ€‘based processing.

### Business Problem

* Full reloads caused delays
* High compute cost
* No near realâ€‘time visibility

### Solution Summary

* ADF watermarkâ€‘based ingestion
* Databricks deduplication & merge logic
* Synapse analytics layer
* Power BI operational dashboards

### Business Impact

* Pipeline runtime reduced by **70%**
* Monthly compute costs reduced
* Near realâ€‘time operational insights

---

## ðŸ—ï¸ Architecture Diagram (Description)

**Flow:**
Source â†’ ADF (Watermark) â†’ ADLS Raw â†’ Databricks (Merge) â†’ ADLS Curated â†’ Synapse â†’ Power BI

---

## ðŸ”§ Incremental Logic

* Maintain control table for last processed timestamp
* Filter source data using watermark
* MERGE INTO curated tables

---

## ðŸ“„ Monitoring & Governance

* Pipeline success/failure logging
* Costâ€‘efficient compute scaling
* Data quality checks

---

# ðŸ“š Shared Documentation

## KPI Definitions

* Fleet Utilization = Active Time / Available Time
* Reporting Latency = Source to Dashboard SLA

## Assumptions

* Data refreshed daily or near realâ€‘time
* ZAR as reporting currency

---

**This documentation is designed to be interviewâ€‘ready, recruiterâ€‘friendly, and enterpriseâ€‘grade.**
